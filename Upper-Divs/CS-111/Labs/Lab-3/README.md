# Hash Hash Hash

In this lab, we have explored the implementation of a safe, concurrent hash table using two different locking strategies and C `pthread`s.

## Building

Build the program in the root directory using the Makefile:

```
make
```

## Running

The program can be run as follows:

```
./hash-table-tester -t 2 -s 200000
```

The expected output should be something along the lines of:

```
Generation: 121,451 usec
Hash table base: 2,012,466 usec
  - 0 missing
Hash table v1: 2,745,427 usec
  - 0 missing
Hash table v2: 868,164 usec
  - 0 missing
```

Where time is measured in microseconds, and `Generation` is the time it takes to generate the hash table, `Hash table base` is the time taken to run the base hash table, `Hash table v1` is the time taken to run hash table v1, and `Hash table v2` is the time taken to run hash table v2. Below each value is the number of values missing during runtime, which should be 0 if the program is free of data races. `Hash table v1` should take longer than `Hash table base`, while `Hash table v2` should take noticeably less time than both `Hash table base` and `Hash table v1`. Exact times will change between tests.

## First Implementation

The first implementation (using a single mutex) works by creating a critical section around the entire `hash_table_v1_add_entry` function. This ensures that there can only be a single thread attempting to add an entry at a given time, guaranteeing that no two threads can be modifying the hash table in a way that generates a data race. This critical section is created through the use of a single mutex that belongs to an individual hash table, and is initialized and destroyed when the hash table is. Since there is only a single mutex, deadlocks don't need to be worried about.

### Performance

The following 2 calls were executed:

```
./hash-table-tester -t 2 -s 200000
./hash-table-tester -t 4 -s 100000
```

Despite the difference in thread usage, both tests executed in approximately the same time. This time (around 2.5s) was slower than the base implementation (around 2s). This is because all the work of adding new hash table entries is still being done sequentially, since the entire `hash_table_v1_add_entry` function is protected by a mutex. This results in the multithreading implementation having next to no real improvements over the base implementation. Since locking mutexes also has overhead, the multithreading is actually harmful to the performance of the program. Since only one thread was able to enter that function at a given time, increasing or decreasing the number of threads didn't have any impact either.

## Second Implementation

This implementation follows the same idea as the first implementation. We initialize our mutexes when the hash table is created, use them to protect a critical section of our code in `hash_table_v2_add_entry`, and then destroy them when the hash table is destroyed. The main difference comes from the granularity of these mutexes. Instead of giving each hash table a mutex, which forces any modifications of the hash table to occur in sequence, we give each hash table entry a mutex, allowing for parallel modifications to be possible, as long as the threads are modifying different entries. We then proceed to lock the appropriate hash table entry once we determine the hash table entry of a given element, and then unlock it once all modifications are made. Race conditions in this program are generated by two threads attempting to add an element to the same hash table entry at once, resulting in one of the elements being lost. Since we ensure that no two threads can modify the same hash table entry at once, we achieve the same security brought by locking the entire hash table. Finally, since we exhibit no "hold and wait" behavior (our threads will acquire a lock and then release the lock before attempting to acquire another lock), deadlock is impossible.

### Performance

Run the tester such that the base hash table completes in 1-2 seconds. Report the relative speedup with number of threads equal to the number of physical cores on your machine (at least 4). Note again that the amount of work (`-t` times `-s`) should remain constant. Report the speedup relative to the base hash table implementation. Explain the difference between this implementation and your first, which respect why you get a performance increase.

The following 2 calls were executed:

```
./hash-table-tester -t 2 -s 200000
./hash-table-tester -t 4 -s 100000
```

This hash table executed significantly faster (about 2.5-3x) than either the base hash table or hash table v1. This is because this implementation is actually able to exploit multithreading. In the base hash table, only one thread executes the program. In hash table v1, only one can modify the hash table at a given time, essentially limiting it to sequential execution, despite the existence of multiple threads. In v2, however, we allow multiple threads to share the workload by only locking individual hash table entries, resulting in the ability for all of our threads to work at once. As long as threads are attempting to access different hash table entries, they can work in parallel, resulting in this much faster execution. Unlike v1, changing the number of threads we're using does affect the runtime. Since we're allowing our program to make use of all the threads we tell it to generate, allocating less threads results in a worse runtime, since there will be less threads to split the work. In our case, using 2 threads takes around 1.3s, while using 4 threads takes around 0.8s.

## Cleaning up

Binary files can be cleaned out of the filesystem using:

```
make clean
```
